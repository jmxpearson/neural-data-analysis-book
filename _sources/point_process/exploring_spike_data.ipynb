{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(exploring-spike-data)=\n",
    "# Exploring neural spike data\n",
    "\n",
    "In this section, we'll be exploring single unit electrophysiology data recorded by Tim Darlington in Lisberger Lab. The data are recordings from three units in macaque frontal eye field (FEF) stored in Matlab's `.mat` format and consist of three variables:\n",
    "\n",
    "- `spikes`: a cell array in which each cell contains an array of spike timestamps (trials x units, measured in milliseconds)\n",
    "- `H` and `V`: horizontal and vertical eye positions (trials x time points, sampled at 1000 samples per second)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{admonition} Exercise\n",
    "1. Download the data from Google Drive. In Colab, you can do this by running \n",
    "    ```bash\n",
    "    !gdown --id 1bsqBXmV0SrMwycyRR0jY5gyw7wqjYQI_\n",
    "    ``` \n",
    "    where the long string is the file's Google Drive identifier. \n",
    "\n",
    "1. Load the data. You will want to `import scipy.io` and use [`loadmat`](https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.io.loadmat.html) to load the data. The result is a dictionary with each key a variable.\n",
    "\n",
    "1. Write code that extracts the number of units, trials, and timepoints from the data.\n",
    "\n",
    "````"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# 1. Download the data\n",
    "\n",
    "!gdown --id 1bsqBXmV0SrMwycyRR0jY5gyw7wqjYQI_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# 2. Load the data\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "mat_dict = scipy.io.loadmat(\"fef_spikes.mat\")\n",
    "spikes = mat_dict[\"spikes\"]\n",
    "H,V = mat_dict[\"H\"], mat_dict[\"V\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# 3. Write code that extracts the number of units, trials,\n",
    "#    and timepoints from the data.\n",
    "\n",
    "n_trials = spikes.shape[0]\n",
    "n_units = spikes.shape[1]\n",
    "n_timepoints = H.shape[1]\n",
    "print(f\"Number of trials: {n_trials}\\nNumber of units: {n_units}\\nNumber of time points: {n_timepoints}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting from events to time series\n",
    "\n",
    "As we learned about in [the previous section](psth-section), we often need to convert from a list of event times to a time series representation of the same data. For instance, rather than listing all times at which a spike occurred, we might want to know how many spikes occurred at each moment in time. That is, we'd like to make a histogram of spike counts using some small bin size.\n",
    "\n",
    "To perform the conversion, we'll start by taking only a small subset of the data, spikes for a single unit on a single trial, and converting that list to a time series."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Exercise\n",
    "1. Extract the spike times for unit 1 on trial 1.\n",
    "1. Get a count of spikes during each millisecond of the trial. Note that spike timestamps are recorded in milliseconds.\n",
    "1. Write a test or tests to check whether you got the right answer. Each test should be a line of code that evaluates to true or false based on the raw data and time series. (Hint: tests often check mathematical properties that should be true both before and after some operation is performed.)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# 1. Extract the spike times for unit 1 on trial 1\n",
    "\n",
    "spks = spikes[0,0].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# 2. Get spike counts\n",
    "\n",
    "hist, bin_edges = np.histogram(spks, bins=range(n_timepoints+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# 3. Write tests\n",
    "\n",
    "# sum over histogram = # total spikes\n",
    "print(sum(hist) == spks.size)\n",
    "\n",
    "# the locations of the nonzero histogram bins are \n",
    "# the timestamps of the spikes (rounded down)\n",
    "print(np.all(hist.nonzero()[0] == np.floor(spks)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactor: multiple trials and units\n",
    "Now that you have code that works on a single list, you can generalize to code that works on multiple trials and multiple units.\n",
    "\n",
    "```{admonition} Exercise\n",
    "1. Generalize your code to do this conversion over multiple trials and units. The result should be a time points x trials x units array.\n",
    "1. Extend your test code to perform the same sets of checks on the array created by this new code.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# 1. Generalize over multiple trials and units. \n",
    "\n",
    "bins = range(n_timepoints+1)\n",
    "spkbin = np.zeros((n_timepoints, n_trials, n_units))\n",
    "for i, trial in enumerate(spikes):\n",
    "    for j, unit in enumerate(trial):\n",
    "        spkbin[:,i,j] = np.histogram(unit.flatten(), bins)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# 2. Perform the same sets of checks on the array. \n",
    "\n",
    "for i in range(n_trials):\n",
    "    for j in range(n_units):\n",
    "        if not sum(spkbin[:,i,j]) == spikes[i,j].size:\n",
    "            print(\"Test 1 failed\")\n",
    "        if not np.all(spkbin[:,i,j].nonzero()[0] == np.floor(spikes[i,j])):\n",
    "            print(\"Test 2 failed\")\n",
    "print(\"All tests passed\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactor: make it a function\n",
    "Once we have a pattern in code we know we'll be repeating, it's helpful to pull it into a function for several reasons:\n",
    "\n",
    "- **Functions make our code more readable.** Functions give names to blocks of code, and when we choose these names to reflect what the code does, the flow of logic in our program becomes clearer.\n",
    "- **Functions help keep our code [DRY](https://en.wikipedia.org/wiki/Don't_repeat_yourself).** When changes need to be made, we only have to edit one location.\n",
    "- **Functions make our code safer.** Does your code create lots of temporary little variables that you need only for intermediate steps. Do you sometimes reuse these variable names later? Functions have well-defined inputs and outputs, but all other variables inside only exist for the lifetime of the function. This keeps our workspace neater and avoids some subtle bugs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Exercise\n",
    "1. Pull your spike binning code into a function. That function should take as input a cell array like the `spikes` variable, a minimum, and a maximum time, and return the same kind of spike count array as before.\n",
    "1. Make sure your tests still pass on the output of the function.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# 1. Binning code as a function. Times assumed to be in ms. \n",
    "\n",
    "def spikes_to_bin(spikes, t_min, t_max):\n",
    "    if t_max < t_min:\n",
    "        return np.zeros((0,n_trials,n_units))\n",
    "    bins = range(t_min,t_max+1)\n",
    "    spkbin = np.zeros((t_max-t_min, n_trials, n_units))\n",
    "    for i, trial in enumerate(spikes):\n",
    "        for j, unit in enumerate(trial):\n",
    "            spkbin[:,i,j] = np.histogram(unit.flatten(), bins)[0]\n",
    "    return spkbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# 2. Make sure tests still pass.\n",
    "\n",
    "def test(spkbin, spikes, t_min, t_max):\n",
    "    for i in range(n_trials):\n",
    "        for j in range(n_units):\n",
    "            spk_trial = spikes[i,j].flatten()\n",
    "            spks = spk_trial[(t_min <= spk_trial) & (spk_trial <= t_max)]\n",
    "            if not sum(spkbin[:,i,j]) == spks.size:\n",
    "                print(\"Test 1 failed for trial %i, unit %i, t_min: %i, t_max: %i\" % (i,j,t_min,t_max))\n",
    "                return\n",
    "            # If there is a spike at t_max, we consider it to fall between [t_max-1,t_max], inclusive\n",
    "            if np.any(spks == t_max):\n",
    "                spks[spks == t_max] -= 1.\n",
    "            if not np.all(t_min+spkbin[:,i,j].nonzero()[0] == np.floor(spks)):\n",
    "                print(\"Test 2 failed for trial %i, unit %i, t_min: %i, t_max: %i\" % (i,j,t_min,t_max))\n",
    "                return\n",
    "    print(\"All tests passed for t_min: %i, t_max: %i\" % (t_min,t_max))\n",
    "\n",
    "for t_min in [0,100,250,n_timepoints]:\n",
    "    for t_max in [0,100,250,n_timepoints]:\n",
    "        if t_max <= t_min: continue\n",
    "        spkbin = spikes_to_bin(spikes, t_min=t_min, t_max=t_max)\n",
    "        test(spkbin, spikes, t_min=t_min, t_max=t_max)        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactor: generalizing to different bin widths\n",
    "\n",
    "There are plenty of cases where we'd like to get spike counts over larger bins.\n",
    "\n",
    "```{admonition} Exercise\n",
    "1. Generalize your function to take a bin width as a parameter.\n",
    "1. Make sure your tests still pass on the output of the function.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# 1. Function with bin width as a parameter. Times assumed to be in ms.\n",
    "\n",
    "def spikes_to_bin_varwidth(spikes, t_min=0, t_max=n_timepoints, bin_width=1):\n",
    "    if t_max < t_min:\n",
    "        return np.zeros((0,n_trials,n_units))\n",
    "    bins = np.arange(t_min,t_max+bin_width,bin_width)\n",
    "    spkbin = np.zeros(((t_max-t_min)//bin_width, n_trials, n_units))\n",
    "    for i, trial in enumerate(spikes):\n",
    "        for j, unit in enumerate(trial):\n",
    "            spkbin[:,i,j] = np.histogram(\n",
    "                unit.flatten(),\n",
    "                bins)[0]\n",
    "    return spkbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# 2. Make sure tests still pass.\n",
    "\n",
    "for t_min in [0,100,250,n_timepoints]:\n",
    "    for t_max in [0,100,250,n_timepoints]:\n",
    "        if t_max <= t_min: continue\n",
    "        spkbin = spikes_to_bin_varwidth(spikes, t_min=t_min, t_max=t_max, bin_width=1)\n",
    "        test(spkbin, spikes, t_min=t_min, t_max=t_max)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing spike data\n",
    "\n",
    "A common format for displaying raw event data is the raster plot, in which each row represents one trial, time increases along the horizontal axis, and events are indicated by dots or tick marks.\n",
    "\n",
    "With our array of spike counts in time, we have all we need to construct the simplest version of this plot. If we think of the first two dimensions of the count array (time and trial) as dimensions of an image, we can plot one image per unit by taking a slice of the count array and using plotting the result as pixels.\n",
    "\n",
    "```{admonition} Exercise\n",
    "1. Plot a PSTH using the data in the count array. Time should be the *horizontal* axis. (Hint: [`matshow`](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.matshow.html) scales the colormap to the range of data.)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "# 1. Raster plot of spike data \n",
    "t_min = 0\n",
    "t_max = n_timepoints\n",
    "bin_width = 10\n",
    "spk_bin = spikes_to_bin_varwidth(spikes, bin_width=bin_width)\n",
    "X, Y = np.mgrid[slice(t_min, t_max + bin_width, bin_width), slice(0,n_trials+1,1)]\n",
    "vmax = spk_bin.max()\n",
    "fig, axes = plt.subplots(1,3,figsize=(11,2));\n",
    "for n, ax in enumerate(axes):\n",
    "    im = ax.pcolormesh(X, Y, spk_bin[:,:,n], vmin=0, vmax=vmax)\n",
    "    ax.set_title(\"Unit \" + str(n+1))\n",
    "    ax.set_xlabel(\"Time (ms)\")\n",
    "    if n == 0: \n",
    "        ax.set_ylabel(\"Trial\")\n",
    "    else:\n",
    "        ax.set_yticks([])\n",
    "plt.subplots_adjust(hspace=0.1)\n",
    "cbar = fig.colorbar(im,ax=axes)\n",
    "cbar.set_label(\"Spike count\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactor: adding behavior\n",
    "\n",
    "We might also like to compare spiking with behavior. We can use the [`subplots`](https://matplotlib.org/gallery/subplots_axes_and_figures/subplots_demo.html) command to make multipanel figures that facilitate comparisons between the two. Let's make a figure with three rows and a single column that plot spiking, the horizontal, and the vertical eye positions as a function of time.\n",
    "\n",
    "```{admonition} Exercise\n",
    "1. Make the plot described above. Make sure the axes align. (Hint: you may want to use `xlim` and `ylim` to adjust for alignment and better readability.) Eye traces should all be plotted in the same color. Each panel should be titled.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# 1. Make a figure with behavior.\n",
    "\n",
    "fig, axes = plt.subplots(3,1,figsize=(4,9));\n",
    "im1 = axes[0].pcolormesh(X,Y,spk_bin[:,:,0]);\n",
    "im2 = axes[1].pcolormesh(H,cmap=\"jet\")\n",
    "im3 = axes[2].pcolormesh(V,cmap=\"jet\")\n",
    "plt.colorbar(im1,ax=axes[0])\n",
    "plt.colorbar(im2,ax=axes[1])\n",
    "plt.colorbar(im3,ax=axes[2])\n",
    "axes[0].set_title(\"Unit 1\")\n",
    "axes[1].set_title(\"Horizontal position\")\n",
    "axes[2].set_title(\"Vertical position\")\n",
    "for i in range(3):\n",
    "    axes[i].set_ylabel(\"Trials\")\n",
    "axes[2].set_xlabel(\"Time (ms)\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactor: make it a function\n",
    "\n",
    "For plots we make often, it can be useful to repackage code into a function.\n",
    "\n",
    "```{admonition} Exercise\n",
    "1. Create a function to produce this plot. The function should take all needed data as inputs and only handle the plotting and layout.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# 1. In function form:\n",
    "\n",
    "def plot_summary(unit, spk_bin, H, V):\n",
    "    fig, axes = plt.subplots(3,1,figsize=(4,9));\n",
    "    im1 = axes[0].pcolormesh(X, Y, spk_bin[:,:,unit]);\n",
    "    im2 = axes[1].pcolormesh(H,cmap=\"jet\")\n",
    "    im3 = axes[2].pcolormesh(V,cmap=\"jet\")\n",
    "    plt.colorbar(im1,ax=axes[0])\n",
    "    plt.colorbar(im2,ax=axes[1])\n",
    "    plt.colorbar(im3,ax=axes[2])\n",
    "    axes[0].set_title(\"Unit 1\")\n",
    "    axes[1].set_title(\"Horizontal position\")\n",
    "    axes[2].set_title(\"Vertical position\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "plot_summary(2, spk_bin, H, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove('fef_spikes.mat')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9e02e0b94c2bdff7abf49239ef598c5e519e47cb46f883733d825e84045e64b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
