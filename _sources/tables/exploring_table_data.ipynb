{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(exploring-table-data)=\n",
    "# Exploring table data\n",
    "This week, our in-class work will focus on two topics in tandem. First, we'll be getting practice with handling real-world tabular data using Pandas. Second, we'll be thinking about how we deal with sex differences in neuroscience and sex as a biological variable.\n",
    "\n",
    "Let's tackle those in reverse. Since 2016, NIH has required that its projects properly account for [sex as a biological variable](https://orwh.od.nih.gov/sex-gender/nih-policy-sex-biological-variable) in research designs. To grossly oversimplify, if females make up 50% of the human population we hope to benefit, you need to have a strong reason for only using only a single sex (usually males) in your study. Of course, there are such reasons (some courtship behaviors, maternal behavior), but the purpose of the policy is to move researchers away from viewing \"male\" as a biological default.\n",
    "\n",
    "As several papers have pointed out (e.g. {cite:t}`shansky2021considering`) this will require a shift in thinking. Not only because it's typical to treat female physiology as more complicated {cite:p}`shansky2019hormones` but because underpowered or misinterpreted studies on sex differences have been used to reinforce stereotypes {cite:p}`grissom2019let`. For this reason, it's important to think in a methodologically rigorous way about how we investigate sex differences, even when they're not the primary aim of our research. \n",
    "\n",
    "Our data this week come from a recent study in this vein from {cite:t}`chensexdiffs2021` at the University of Minnesota, who examined sex differences in mice performing a restless bandit task. Briefly, the task presents animals with two options, both of which are (probabilistically) rewarded but whose values change in time. This requires animals to trade off exploiting an option with known value against exploring the value of an option they haven't chosen in a while. As the authors report in the paper, while both sexes achieved the same reward rates in the task, the strategies they used to do so differed in interesting ways.\n",
    "\n",
    "Fortunately, the authors posted their data to an [online repository](https://datadryad.org/stash/dataset/doi:10.5061/dryad.z612jm6c0) (yay open science!). If you're working locally, you can download from this link. If not, you can start your Colab notebook with the following cell, which will download the data and unzip it for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl --output tmp.zip -L -X GET \"https://datadryad.org/api/v2/datasets/doi%3A10.5061%2Fdryad.z612jm6c0/download\" -H \"accept: application/zip\"\n",
    "unzip tmp.zip\n",
    "unzip cleaned_up_restless_final_data.zip\n",
    "rm tmp.zip\n",
    "rm README.txt\n",
    "rm cleaned_up_restless_final_data.zip\n",
    "chmod -R u+wx cleaned\\ up\\ restless\\ final\\ data\n",
    "mv cleaned\\ up\\ restless\\ final\\ data data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files are in the `data` folder, with one subfolder for each session. Animals 1&ndash;16 are male, 17&ndash;32 female. Our goal for today will be to aggregate all this data into a single tidy data frame that we can use to perform some exploratory plotting."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading table data\n",
    "The most common format for storing tabular data is in comma-separated\n",
    "value or `.csv` format, in which each line of the file contains a row of\n",
    "the table, with columns separated by commas. Often, the first line of the\n",
    "file lists the column names, also separated by commas.\n",
    "\n",
    "```{admonition} Exercise\n",
    "1. Start by loading the data for a single session and a single animal into Pandas. This can be done via the `pandas.read_csv` function. Note that the first column of the `csv` file is an index, so you might want to provide the `index_col=0` keyword argument.\n",
    "\n",
    "1. Print the first 5 rows of the table. What are the column names? What is a way to find this out without printing the table directly (i.e., what if you had to find this out within a function)?\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# import pandas package\n",
    "import pandas as pd\n",
    "\n",
    "# load data from a csv into a table\n",
    "data_path = 'data/'\n",
    "dat = pd.read_csv(data_path + 'session1/1.csv', index_col=0)\n",
    "dat.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# get column names without printing\n",
    "dat.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First plots\n",
    "As we did last week, let's try out some ideas on this small chunk of data by making plots.\n",
    "\n",
    "```{admonition} Exercise\n",
    "1. The `left` and `right` columns list the probability reward for nosepokes to the left and right targets on each trial. Plot the values of both of these over time. What would the optimal strategy for the mice be in this situation if they knew this information? How should this change if they _don't_ know the values?\n",
    "\n",
    "1. The `choice` variable is coded `1` for a left choice and `2` for a right choice. Make a plot that shows how choices track reward probabilities for the two options. Since choice only has two values, you might want to smooth the series. You can either adopt the convolutional approach we used last week or use the Pandas [windowing operations](https://pandas.pydata.org/docs/user_guide/window.html#window-generic).\n",
    "\n",
    "1. Plot the cumulative reward earned by the animal as a function of trial in the session.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "# plot left and right values over time\n",
    "\n",
    "plt.plot(dat[['left', 'right']])\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('Reward probability')\n",
    "plt.ylim(0, 1);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{toggle}\n",
    "If the mice _knew_ the values, they would choose whichever is maximal at a given time. If they _don't_ know the values of each option, they need to estimate them, and explore when it's likely another option is better. (Actually, calculating the optimal strategy in situations like this is a surprisingly rich mathematical problem.)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# plot choice probability\n",
    "\n",
    "choice_prob = dat.choice.rolling(10).mean() - 1  # 10-bin window by default, this will use the *past only*\n",
    "plt.plot(choice_prob - 0.5, label='choice probability - 0.5')\n",
    "plt.plot(dat.right - dat.left, label='right - left reward probability')\n",
    "plt.legend(loc=1, bbox_to_anchor=(1.55, 1))\n",
    "plt.xlabel('Trial')\n",
    "plt.title('Choice tracks reward probability');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "#plot cumulative reward\n",
    "\n",
    "plt.plot(dat.reward.cumsum())\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('Cumulative Reward');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining data sets\n",
    "With these simple analyses under our belt, we can think about how we want to analyze data for all the animals combined. There are two basic approaches:\n",
    "- Loop over data sets, applying the same analysis to each one. Then write out the results to disk or hold them all in a list in memory.\n",
    "- Combine all the data together into a single `DataFrame` object that can be easily manipulated for a wide variety of analyses."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidying data\n",
    "Many data tables are structured with multiple observations in each row, but for many analysis and visualization needs, data are better structured as one observation per row or [\"tidy\" data](https://www.jstatsoft.org/article/view/v059i10). While not perfect for all purposes, tidy data provides a method for canonicalizing data so that software can focus on transferring to and from a fixed form.\n",
    "\n",
    "In Pandas, the key functions for this purpose are [`melt`](https://pandas.pydata.org/docs/reference/api/pandas.melt.html) and [`stack`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.stack.html), along with several others. For a more full-featured approach in R, see [tidyverse](https://www.tidyverse.org) and the comparison [here](https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_r.html).\n",
    "\n",
    "\n",
    "```{admonition} Exercise\n",
    "1. Given that each `csv` file contains data from one session from one animal, what additional columns do we need to put the final _combined_ data frame into tidy format?\n",
    "\n",
    "1. Write code that performs this conversion for _a single dataset_:\n",
    "    - Load the data set.\n",
    "    - Add columns for the session, subject number, and sex of the animal. Note that these will be the same for the entire data set.\n",
    "    - Makes the index (trial number) into a new column called `trial`. Hint [`reset_index`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html).\n",
    "\n",
    "1. Is there any additional information you will need to _uniquely_ identify each row? Can that be added at this stage?\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# add columns to make the dataframe tidy\n",
    "# we need columns for session and subject\n",
    "\n",
    "chunk = pd.read_csv(data_path + 'session1/1.csv', index_col=0)\n",
    "session = 1\n",
    "sub = 1\n",
    "\n",
    "# add columns for session and subject\n",
    "chunk['session'] = session\n",
    "chunk['subject'] = sub\n",
    "if sub <= 16:\n",
    "    chunk['sex'] = 'M'\n",
    "else:\n",
    "    chunk['sex'] = 'F'\n",
    "\n",
    "# make a trial column by resetting the current index and renaming to trial\n",
    "chunk = chunk.reset_index()\n",
    "chunk = chunk.rename(columns={\"index\": \"trial\"})\n",
    "\n",
    "chunk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data in multiple directories\n",
    "Now that we can load and add needed information to each data chunk, we have to think about how to systematically go through subdirectories and load data. For this, we'll use the `walk` function from the `os` module, which takes a directory name as input and returns a generator we can loop over. Our overall strategy will be to walk through the directory, loading all the `csv` files, process each one, hold the results in a list, and use [`concat`](https://pandas.pydata.org/docs/reference/api/pandas.concat.html) to combine them into a single data frame at the end.\n",
    "\n",
    "This bit can be a little tricky, so we'll break it down in pieces:\n",
    "\n",
    "```{admonition} Exercise\n",
    "1. Write a loop that simply prints the information given by `os.walk` as we go through the data directory. Which of these pieces do you need?\n",
    "\n",
    "1. We don't need to process all the directories returned by this process. Write code to prevent us from doing so.\n",
    "\n",
    "1. Write code that extracts the session number from the directory name. Remember that `int` converts a string to an integer.\n",
    "\n",
    "1. Write code that ensures we only process files that end in `.csv`.\n",
    "\n",
    "1. Write code that gets the subject number from the file name.\n",
    "\n",
    "1. Using the code you wrote above, add session, subject, sex, and trial columns to the data set.\n",
    "\n",
    "1. Append this data frame to the list you're using to hold the results.\n",
    "\n",
    "1. Finally, concatenate the results list to form a new data frame. Note that the index is not unique, so for technical reasons, it will help to `reset_index` again to get a unique index for each row.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "chunk_list = []\n",
    "for (dirname, _, files) in list(os.walk(data_path)):\n",
    "  folder = dirname.split('/')[-1]\n",
    "  if 'session' in folder:\n",
    "    session = int(folder[7:])  # make it an integer\n",
    "    for fname in files:\n",
    "      if fname.endswith('.csv'):\n",
    "        sub = int(fname.split('.')[0])  # make it an integer\n",
    "        chunk = pd.read_csv(dirname + '/' + fname, index_col=0)\n",
    "\n",
    "        # add columns for session and subject\n",
    "        chunk['session'] = session\n",
    "        chunk['subject'] = sub\n",
    "        if sub <= 16:\n",
    "          chunk['sex'] = 'M'\n",
    "        else:\n",
    "          chunk['sex'] = 'F'\n",
    "        \n",
    "        # make a trial column by resetting the current index and renaming to trial\n",
    "        chunk = chunk.reset_index()\n",
    "        chunk = chunk.rename(columns={\"index\": \"trial\"})\n",
    "        \n",
    "        chunk_list.append(chunk)\n",
    "\n",
    "print(\"Total number of chunks: {}\".format(len(chunk_list)))\n",
    "\n",
    "\n",
    "# concatenate all data frames together\n",
    "\n",
    "dat = pd.concat(chunk_list).reset_index(drop=True)  # overwrites our old dat variable!\n",
    "dat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group-level statistics\n",
    "Having data in tidy format can facilitate easier comparisons across observation types. In Pandas, the relevant code pattern is to call [`groupby`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) on the `DataFrame`, followed by a call to a summary statistic like `mean` or `std`. That is, if `data` is a `DataFrame`:\n",
    "```python\n",
    "data.groupby(by=['column1', 'column5']).mean()\n",
    "```\n",
    "will calculate a groupwise mean. More generally, this pattern of breaking data into chunks based on a combination of variables, performing some analysis, and aggregating the results is known as [Split-Apply-Combine](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html).\n",
    "\n",
    "```{admonition} Exercise\n",
    "1. Use `groupby` to calculate the mean and variance of the reaction time for each animal in each session.\n",
    "```\n",
    "\n",
    "### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "dat.groupby(['subject', 'session']).RT.agg(['mean', 'var'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory plotting redux\n",
    "Now let's try to generalize our plot above of accumulated rewards over time. This time, however, we'd like to plot accumulated rewards for _all animals_ across _all sessions_. As you might expect, `groupby` will be our friend, but we'll have to figure out how to calculate the information we need. As we'll see, it's easiest to do this by adding the new variables as columns to our data frame.\n",
    "\n",
    "### The final tidy\n",
    "````{admonition} Exercise\n",
    "1. To make sure the steps below work, we need to start by sorting the data frame by subject and session. (Be sure to save the result or use `inplace=True`!)\n",
    "\n",
    "1. Using `groupby`, calculate the cumulative reward for each subject and each session as we did for a single dataset above. Assign this to a new column in the data frame.\n",
    "\n",
    "1. Similarly, calculate the cumulative reward for each subject _across all sessions_ and assign this as a different column in the dataframe.\n",
    "\n",
    "1. The one relevant piece of information we still don't have, the one that would uniquely identify each row and make the data frame tidy, is a _unique_ trial number for each animal across sessions. If `dat` is the data frame and `trial` is the column containing the (within-session) trial number, the following line of code creates such a column:\n",
    "```python\n",
    "dat['cumulative_trial'] = dat.groupby(['subject']).trial.transform(lambda x: x.reset_index().index)\n",
    "```\n",
    "How does this work?\n",
    "````\n",
    "\n",
    "#### Solution:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{toggle}\n",
    "The strategy here is as follows:\n",
    "1. Group the data frame into chunks, one per subject.\n",
    "1. Pull out the column we want.\n",
    "1. Perform some transformation (e.g., cumulative sum).\n",
    "1. Assign the result back as a new column.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "dat = dat.sort_values(by=['subject', 'session'])\n",
    "dat['cumulative_reward_session'] = dat.groupby(['subject', 'session']).reward.cumsum()\n",
    "dat['cumulative_reward_lifetime'] = dat.groupby(['subject']).reward.cumsum()\n",
    "dat['cumulative_trial'] = dat.groupby(['subject']).trial.transform(lambda x: x.reset_index().index)\n",
    "dat.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why did we do all this?\n",
    "The above approach &mdash; adding a bunch of variables to our data frame rather than extracting what we need &mdash; might seem like overkill, but as R users know, the approach really shines when we want to start grouping our analyses by different sets of variables. As an example, with our expanded data set, Seaborn easily lets us easily make both of the following plots with a simple variation in the same command:\n",
    "\n",
    "```{admonition} Exercise\n",
    "1. Using `lineplot`, plot cumulative reward across all sessions, aggregating by sex. (Hint: since `lineplot` automatically calculates bootstrapped confidence intervals and this can take a long time for big datasets, you might want to supply the keyword `ci=None`.)\n",
    "\n",
    "1. Make the same plot, showing cumulative rewards for all individuals.\n",
    "```\n",
    "\n",
    "#### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 3))\n",
    "sns.lineplot(ax=ax[0], data=dat, x='cumulative_trial', \n",
    "             y='cumulative_reward_lifetime', hue='sex', errorbar=None)\n",
    "sns.lineplot(ax=ax[1], data=dat, x='cumulative_trial', \n",
    "             y='cumulative_reward_lifetime', hue='subject', errorbar=None, legend=None)\n",
    "ax[0].set_xlabel('Total Trials')\n",
    "ax[1].set_xlabel('Total Trials')\n",
    "ax[0].set_ylabel('Total Rewards')\n",
    "ax[1].set_ylabel('Total Rewards')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a97c0be00662db3bed8fe12bace3dd68dcba4f9aa04406cb661d7504ba5e85ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
