{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Image data\n",
    "In this session, we'll continue our analysis of orientation and motion tuning in the calcium imaging sample from mouse V1. Our first step will be to refactor our current tuning analysis into a function, making it easier to swap out our method for determining preferred orientation while keeping the rest of our code the same (aka, the [strategy pattern](https://en.wikipedia.org/wiki/Strategy_pattern)). The second step will be to write code that calculates tuning across the entire image.\n",
    "\n",
    "```{important}\n",
    "In this lesson, we will only be considering the simplest type of analysis &mdash; analyzing images at the pixel level. For any serious analysis, you would want to use packages like [Suite2p](https://www.suite2p.org) or [CaImAn](https://caiman.readthedocs.io/en/master/) that detect regions of interest (ROIs), typically cell bodies, and extract their time courses.\n",
    "```\n",
    "\n",
    "## Tuning curves: refactoring\n",
    "Before we start, let's clean up our code:\n",
    "\n",
    "```{admonition} Exercise\n",
    "1. Rewrite your code for finding the preferred stimulus as a function.\n",
    "1. Write code that finds the preferred orientation for each pixel in the image.\n",
    "1. Display the result as a color-mapped image:\n",
    "    - To get a colormap with `n` values, use, e.g., `cm.get_cmap('jet', n)` (explanations [here](https://matplotlib.org/tutorials/colors/colormap-manipulation.html) and [here](https://jakevdp.github.io/PythonDataScienceHandbook/04.07-customizing-colorbars.html)).\n",
    "    - To set the colormap for the current image, use `cmap=<cmap name>`, where `<cmap name>` is a colormap name. There are [lots to choose from](https://matplotlib.org/stable/tutorials/colors/colormaps.html).\n",
    "    - You will want to create a discrete color axis by assigning each value in the array to a color. This is illustrated in [PDSH](https://jakevdp.github.io/PythonDataScienceHandbook/04.07-customizing-colorbars.html#Discrete-Color-Bars).\n",
    "1. What do you note about the resulting image? What does or doesn't make sense biologically?\n",
    "```\n",
    "\n",
    "```{warning}\n",
    "The image can take a while to plot (> 1 minute on a decent machine), so you may want to settle for plotting a smaller section of the image while you debug.\n",
    "```\n",
    "\n",
    "### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!gdown 10mbjgJIkyaczKs47_f4es0M3AI7gqTy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sci\n",
    "\n",
    "vars = sci.loadmat('DirectionTuning_V1_dec.mat')\n",
    "\n",
    "data = vars['data']\n",
    "dirTuningExp = vars['dirTuningExp']\n",
    "\n",
    "Nvert, Nhorz, Nframes = data.shape\n",
    "dt = 1/3  # 3 Hz sampling \n",
    "\n",
    "labels = -1 * np.ones([Nframes, 1])\n",
    "codes = dirTuningExp['tGratingDirectionDeg'][0][0][0]\n",
    "Ntrials = dirTuningExp['nTrials'][0][0][0][0]\n",
    "Noff = dirTuningExp['stimOffFrames'][0][0][0][0]\n",
    "Non = dirTuningExp['stimOnFrames'][0][0][0][0]\n",
    "\n",
    "offset = 0\n",
    "for i in range(Ntrials):\n",
    "    offset = offset + Noff\n",
    "    labels[offset + np.array(range(Non))] = codes[i]\n",
    "    offset = offset + Non"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# write a function that repeats what we did last time\n",
    "# for a single pixel\n",
    "\n",
    "def find_pixel_tuning(tseries, labels):\n",
    "    \"\"\"\n",
    "    Given a time series and labels (-1 = baseline) for the stimulus shown in each \n",
    "    frame, return the preferred direction of the stimulus as an index\n",
    "    into the categories of labels\n",
    "    \"\"\"\n",
    "    \n",
    "    dat = pd.DataFrame(data = {'orientation': labels.ravel(), 'trace': tseries})\n",
    "\n",
    "    # convert labels to categorical variable\n",
    "    dat['orientation'] = dat['orientation'].astype('category')\n",
    "    \n",
    "    ## group stats\n",
    "    tuning = dat.groupby(by = 'orientation').mean()\n",
    "    \n",
    "    # find the max absolute response relative to baseline\n",
    "    baseline = tuning.iloc[0].values\n",
    "    tcurve = tuning.iloc[1:].values - baseline\n",
    "    return np.argmax(tcurve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# now let's repeat for all pixels\n",
    "preferred_img = np.full((Nvert, Nhorz), np.nan)\n",
    "for hh in range(Nhorz):\n",
    "    for vv in range(Nvert):\n",
    "        preferred_img[vv, hh] = find_pixel_tuning(data[vv, hh, :], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "orientations = np.unique(labels[labels != -1])\n",
    "\n",
    "# plot preferred image\n",
    "from matplotlib import cm\n",
    "cmap = cm.get_cmap('jet', orientations.shape[0])\n",
    "cax = plt.imshow(preferred_img, cmap=cmap, aspect='auto')\n",
    "cbar = plt.colorbar(cax)\n",
    "cbar.ax.set_yticks(np.unique(preferred_img))\n",
    "cbar.ax.set_yticklabels(orientations.astype(str));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of this exercise, we'll be improving our methods of calculating and plotting the pixel tuning.\n",
    "\n",
    "## Tuning curves: handling noise\n",
    "If we want to consider our pixel as tuned, or a particular value the preferred value, it will help to have a sense of how confident we can be in our tuning curve.\n",
    "\n",
    "```{admonition} Exercise\n",
    "1. Modify your code to calculate both the mean and the standard error of the mean for both the baseline and each stimulus.\n",
    "    - How do the standard errors for the stimulus and baseline means compare? Why?\n",
    "    - Is the standard error a good measure of variability for this type of data?\n",
    "    - Assuming the standard error is okay, are we over- or under-estimating the variability of the signal? How might we change this?\n",
    "1. How might you test whether a particular value is really a peak, or just a fluctuation due to noise? There are multiple possible strategies. Discuss with me and then implement this change in a new function. Make sure not to use any [magic numbers](https://en.wikipedia.org/wiki/Magic_number_(programming)#Unnamed_numerical_constants). That is, any parameters of your algorithm should be specifiable by callers of your function.\n",
    "1. Re-plot the tuning map.\n",
    "```\n",
    "\n",
    "```{hint}\n",
    "When considering the difference of two Gaussian variables $X$ and $Y$, the variance of their _difference_ is $\\sigma^2_{X - Y} = \\sigma^2_X + \\sigma^2_Y$\n",
    "```\n",
    "\n",
    "### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# wrap the codes as a function\n",
    "def find_pixel_tuning2(tseries, labels, thresh):\n",
    "    \"\"\"\n",
    "    Given a time series and labels (-1 = baseline) for the stimulus shown in each \n",
    "    frame, return the preferred direction of the stimulus as an index\n",
    "    into the categories of labels\n",
    "    \"\"\"\n",
    "    \n",
    "    dat = pd.DataFrame(data = {'orientation': labels.ravel(), 'trace': tseries})\n",
    "\n",
    "    # convert labels to categorical variable\n",
    "    dat['orientation'] = dat['orientation'].astype('category')\n",
    "    \n",
    "    ## group stats\n",
    "    tuning = dat.groupby(by = 'orientation').mean()\n",
    "    sems = dat.groupby(by = 'orientation').sem()\n",
    "    \n",
    "    # calculate get means and standard errors of the means for \n",
    "    # both baseline and stimulus values\n",
    "    baseline = tuning.iloc[0].values\n",
    "    bsem = sems.iloc[0].values\n",
    "\n",
    "    tcurve = tuning.iloc[1:].values - baseline\n",
    "    tsems = sems.iloc[1:].values\n",
    "\n",
    "    peakind = np.argmax(tcurve)\n",
    "    \n",
    "    # and let's be sure this is > 'thresh' standard deviations from baseline\n",
    "    threshold = thresh * np.sqrt(tsems[peakind] ** 2 + bsem ** 2)\n",
    "    if np.abs(tcurve[peakind]) > threshold:\n",
    "        preferred = peakind\n",
    "    else:\n",
    "        preferred = np.nan\n",
    "        \n",
    "    return preferred\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{toggle}\n",
    "Note that sem is a bad measure here for two reasons:\n",
    "1. The signal is only positive (or should be: you can't have negative\n",
    "light), so it's not normally distributed. Standard errors are based on\n",
    "normality assumptions.\n",
    "2. The sem calculation treats every frame as independent, which is\n",
    "clearly wrong. We could do better by averaging frames within trials and\n",
    "calculating the sem across trials, since those numbers are more\n",
    "independent.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# now let's repeat for all pixels\n",
    "preferred_img = np.full((Nvert, Nhorz), np.nan)\n",
    "for hh in range(Nhorz):\n",
    "    for vv in range(Nvert):\n",
    "        preferred_img[vv, hh] = find_pixel_tuning2(data[vv, hh, :], labels, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# plot preferred image\n",
    "cax = plt.imshow(preferred_img, cmap=cmap, aspect='auto')\n",
    "cbar = plt.colorbar(cax)\n",
    "cbar.ax.set_yticks(np.unique(preferred_img[~np.isnan(preferred_img)]))\n",
    "cbar.ax.set_yticklabels(orientations.astype(str));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning curves: tuned at all?\n",
    "It's clear from both biology and the data at hand that not every pixel is even responsive to the stimuli. We would like a way to \"opt out\" of coloring a pixel with a preferred orientation in cases where that doesn't make sense.\n",
    "\n",
    "```{admonition} Exercise\n",
    "1. What test would you use to determine whether or not a pixel is tuned at all? After discussing with me, implement this change in your code?\n",
    "    - This does not need to be a rigorous statistical test (though it could be).\n",
    "    - How will you indicate \"not tuned\" in the return value from your function?\n",
    "1. Re-plot the data. Make sure your colors reflect that some pixels have no apparent tuning.\n",
    "```\n",
    "\n",
    "```{hint}\n",
    "You can use `cmap.set_bad('white')` to plot NaN values in the resulting image as white.\n",
    "```\n",
    "\n",
    "### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def find_pixel_tuning3(tseries, labels, min_baseline, thresh):\n",
    "    # given a time series and labels (converted to categorical later) of the stimulus shown in each frame (-1 =\n",
    "    # baseline), return the preferred direction of the stimulus as an index\n",
    "    # into the categories of labels\n",
    "    \n",
    "    dat = pd.DataFrame(data={'orientation': labels.ravel(), 'trace': tseries})\n",
    "    dat['orientation'] = dat['orientation'].astype('category')\n",
    "    \n",
    "    ## group stats\n",
    "    tuning = dat.groupby(by = 'orientation').mean()\n",
    "    sems = dat.groupby(by = 'orientation').sem()\n",
    "\n",
    "    baseline = tuning.iloc[0].values\n",
    "    bsem = sems.iloc[0].values\n",
    "\n",
    "    tcurve = tuning.iloc[1:].values - baseline\n",
    "    tsems = sems.iloc[1:].values\n",
    "\n",
    "    peakind = np.argmax(tcurve)\n",
    "    \n",
    "    # now we want two conditions:\n",
    "    # 1. baseline needs to be greater than some minimum\n",
    "    # 2. peak activity needs to be more than some given number of standard\n",
    "    #    deviations above that\n",
    "    threshold = thresh * np.sqrt(tsems[peakind] ** 2 + bsem ** 2)\n",
    "    if baseline > min_baseline and np.abs(tcurve[peakind]) > threshold:\n",
    "        preferred = peakind\n",
    "    else:\n",
    "        preferred = np.nan\n",
    "        \n",
    "    return preferred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# now let's repeat for all pixels\n",
    "preferred_img = np.full((Nvert, Nhorz), np.nan)\n",
    "for hh in range(Nhorz):\n",
    "    for vv in range(Nvert):\n",
    "        preferred_img[vv, hh] = find_pixel_tuning3(data[vv, hh, :], labels, 2e4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "cmap.set_bad('black')\n",
    "cax = plt.imshow(preferred_img, cmap=cmap, aspect='auto')\n",
    "cbar = plt.colorbar(cax)\n",
    "cbar.ax.set_yticks(np.unique(preferred_img[~np.isnan(preferred_img)]))\n",
    "cbar.ax.set_yticklabels(orientations.astype(str));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove('DirectionTuning_V1_dec.mat')"
   ]
  }
 ],
 "metadata": {
  "execution": {
   "timeout": 600
  },
  "kernelspec": {
   "display_name": "book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a97c0be00662db3bed8fe12bace3dd68dcba4f9aa04406cb661d7504ba5e85ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
