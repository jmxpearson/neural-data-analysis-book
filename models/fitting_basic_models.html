
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Fitting basic models &#8212; Introduction to Neural Data Analysis</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Fitting simulated models" href="simulation_models.html" />
    <link rel="prev" title="Modeling neural data" href="intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Introduction to Neural Data Analysis</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Introduction to Neural Data Analysis
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../python_intro/intro.html">
   Introduction to Python
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_intro/data_structures.html">
     Basic Programming in Python: Data Structures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_intro/nested_data_structures.html">
     Case Study: Nested Data Structures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_intro/patterns.html">
     Patterns, functions, and duck typing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_intro/arrays.html">
     Working with Array Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_intro/data_frames.html">
     Introduction to Data Frames
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../point_process/intro.html">
   Point process data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../point_process/theory.html">
     A little point process theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../point_process/estimation.html">
     Estimating Poisson processes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../point_process/psth.html">
     The peri-stimulus time histogram
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../point_process/exploring_spike_data.html">
     Exploring neural spike data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../point_process/analyzing_spike_data.html">
     Analyzing neural spike data
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../tables/intro.html">
   Tabular data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../tables/exploring_table_data.html">
     Exploring table data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tables/analyzing_table_data.html">
     Analyzing table data
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../images/intro.html">
   Image data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../images/exploring_image_data.html">
     Exploring Image data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../images/analyzing_image_data.html">
     Analyzing Image data
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../debugging/intro.html">
   Debugging
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../debugging/debugging_i.html">
     Debugging Practicum I
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../debugging/debugging_ii.html">
     Debugging Practicum II
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="intro.html">
   Modeling neural data
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Fitting basic models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="simulation_models.html">
     Fitting simulated models
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../bibliography.html">
   Bibliography
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/jmxpearson/neural-data-analysis-book/main?urlpath=lab/tree/introduction_to_neural_data_analysis/models/fitting_basic_models.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/jmxpearson/neural-data-analysis-book/blob/main/introduction_to_neural_data_analysis/models/fitting_basic_models.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/jmxpearson/neural-data-analysis-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/jmxpearson/neural-data-analysis-book/issues/new?title=Issue%20on%20page%20%2Fmodels/fitting_basic_models.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/models/fitting_basic_models.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multinomial-choice">
   Multinomial choice
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#solution">
     Solution:
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-regression">
   Linear regression
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Solution:
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Fitting basic models</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multinomial-choice">
   Multinomial choice
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#solution">
     Solution:
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-regression">
   Linear regression
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Solution:
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="fitting-basic-models">
<h1>Fitting basic models<a class="headerlink" href="#fitting-basic-models" title="Permalink to this headline">#</a></h1>
<p>To begin this chapter, we’ll focus on fitting two basic models: multinomial choice and linear regression. These models are special because, among other things, they admit very efficient computational solutions. That is, they do not require the sort of brute-force methods we’ll use later in the week to fit more complex models. In both cases, the key to saving computer time will be math, and as a means of understanding the model we’re fitting, we’ll first generate data from it.</p>
<section id="multinomial-choice">
<h2>Multinomial choice<a class="headerlink" href="#multinomial-choice" title="Permalink to this headline">#</a></h2>
<p>Multinomial choice data are simply data drawn from a <a class="reference external" href="https://en.wikipedia.org/wiki/Multinomial_distribution">multinomial distribution</a>. That is, they’re count data from a process where the outcome is discrete and selected from a finite set. The simplest multinomial is a binomial, where the events are heads and tails and the counts are the numbers of heads and tails, but the principle generalizes to, e.g., numbers of selections of each answer on a multiple-choice problem.</p>
<p>A multinomial distribution with <span class="math notranslate nohighlight">\(K\)</span> categories is characterized by a probability vector <span class="math notranslate nohighlight">\(p\)</span> with one entry for each possible outcome <span class="math notranslate nohighlight">\(i = 1\ldots K\)</span>. Naturally, this probability must be normalized, <span class="math notranslate nohighlight">\(\sum_{i=1}^K p_i = 1\)</span>. For any <em>single observation</em>, the outcome is governed by a <a class="reference external" href="https://en.wikipedia.org/wiki/Categorical_distribution">categorical distribution</a> (the categorical distribution for binary outcomes is called the <a class="reference external" href="https://en.wikipedia.org/wiki/Bernoulli_distribution">Bernoulli distribution</a>), where the probability of observing outcome <span class="math notranslate nohighlight">\(i\)</span> is <span class="math notranslate nohighlight">\(p_i\)</span>. When we observe multiple outcomes, the probability of seeing <span class="math notranslate nohighlight">\(n_i\)</span> of each type out of a total of <span class="math notranslate nohighlight">\(\sum_i n_i = N\)</span> is given by the multinomial distribution:</p>
<div class="math notranslate nohighlight">
\[
p(\lbrace n_i\rbrace) = \frac{N!}{n_1!n_2!\cdots n_K!} p_1^{n_1} p_2^{n_2} \cdots p_K^{n_K}
\]</div>
<p>Our goal will be to fit this model to data.</p>
<div class="admonition-exercise admonition">
<p class="admonition-title">Exercise</p>
<ol>
<li><p>Using NumPy’s <a class="reference external" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.multinomial.html"><code class="docutils literal notranslate"><span class="pre">random.multinomial</span></code></a> function, generate a vector of counts from the multinomial distribution with probabilities <code class="docutils literal notranslate"><span class="pre">p</span> <span class="pre">=</span> <span class="pre">[0.1,</span> <span class="pre">0.5,</span> <span class="pre">0.2,</span> <span class="pre">0.2]</span></code>.</p></li>
<li><p>One way of fitting the model above to these data is by selecting the parameter vector <span class="math notranslate nohighlight">\(p\)</span> that maximizes the likelihood (the probability of the data given the parameters) given above. In fact, it is usually simpler to maximize the log of the likelihood, since sums are often easier to compute with than products. Show that the solution</p>
<div class="math notranslate nohighlight">
\[
   p = \left(\frac{n_1}{N}, \frac{n_2}{N}, \ldots, \frac{n_K}{N}\right)
   \]</div>
<p>maximizes the log likelihood and is thus the “best fitting” multinomial model.</p>
</li>
<li><p>Calculate the maximum likelihood estimate of <span class="math notranslate nohighlight">\(p\)</span> for your data. Does it match the one used to generate them? How does this change with <span class="math notranslate nohighlight">\(N\)</span>?</p></li>
</ol>
</div>
<section id="solution">
<h3>Solution:<a class="headerlink" href="#solution" title="Permalink to this headline">#</a></h3>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_formats = [&#39;svg&#39;]

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>  <span class="c1"># set random seed for reproducibility</span>

<span class="n">p</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="n">sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">pvals</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;probabilities = </span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="s2">, sample estimates = </span><span class="si">{</span><span class="n">sample</span><span class="o">/</span><span class="n">N</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>probabilities = [0.1, 0.5, 0.2, 0.2], sample estimates = [0.102 0.492 0.225 0.181]
</pre></div>
</div>
</div>
</div>
<div class="toggle docutils container">
<p><strong>Derivation:</strong></p>
<p>From the experession above for the probability of the counts, <span class="math notranslate nohighlight">\(p(\{n_i\})\)</span>, we have the log likelihood</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L} = n_1 \log p_1 + n_2 \log p_2 + \ldots + n_K \log p_K + C
\]</div>
<p>where <span class="math notranslate nohighlight">\(C\)</span> is a constant that does not depend on any of the <span class="math notranslate nohighlight">\(p_i\)</span>. Now, we would like to find the maximum
of this expression by differentiating with respect to each of the <span class="math notranslate nohighlight">\(p_i\)</span> and setting the result to 0, but
we must remember that the <span class="math notranslate nohighlight">\(p_i\)</span> are not all independent — they must sum to 1. Thus, we replace <span class="math notranslate nohighlight">\(p_K\)</span>
with <span class="math notranslate nohighlight">\(1 - \sum_{i=1}^{K-1} p_i\)</span> and use</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L} = \sum_{j=1}^{K-1} n_j \log p_j + n_K \log \left(1 - \sum_{i=1}^{K-1} p_i\right) .
\]</div>
<p>Differentiating this with respect to a particular <span class="math notranslate nohighlight">\(p_k\)</span> then gives the maximum likelihood condition</p>
<div class="math notranslate nohighlight">
\[
0 = \frac{n_k}{p_k} - \frac{n_K}{1 - \sum_{i=1}^{K-1} p_i} = \frac{n_k}{p_k} - \frac{n_K}{p_K} .
\]</div>
<p>Clearly, this is satisfied only when we have <span class="math notranslate nohighlight">\(n_i/p_i\)</span> equal to a constant for all <span class="math notranslate nohighlight">\(i\)</span>. That is, <span class="math notranslate nohighlight">\(p_i = n_i/A\)</span>.
Recalling that the <span class="math notranslate nohighlight">\(p_i\)</span> must sum to <span class="math notranslate nohighlight">\(1\)</span> while the <span class="math notranslate nohighlight">\(n_i\)</span> sum to <span class="math notranslate nohighlight">\(N\)</span> then gives <span class="math notranslate nohighlight">\(A = N\)</span>, which is the maximum likelihood solution stated above. ■</p>
</div>
<p>Moreover, as <span class="math notranslate nohighlight">\(N\)</span> gets large, the maximum likelihood estimate gets closer and closer to the true probabilities. This property is called <a class="reference external" href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation#Consistency">consistency</a> and is a property shared by most maximum likelihood estimators. (In fact, many of these estimators can be proven to be normally distributed around the correct value for large samples.)</p>
</section>
</section>
<section id="linear-regression">
<h2>Linear regression<a class="headerlink" href="#linear-regression" title="Permalink to this headline">#</a></h2>
<p>Linear regression is the best-studied fitting procedure in all of statistics. Here, we’ll explore two means of fitting a linear model, both based on maximum likelihood, which we’ve already seen is equivalent to minimizing the sum of squared errors.</p>
<div class="admonition-exercise admonition">
<p class="admonition-title">Exercise</p>
<ol>
<li><p>Generate 500 data points from the model</p>
<div class="math notranslate nohighlight">
\[
    y = \beta_0 + \beta_1 x + \varepsilon
    \]</div>
<p>with <span class="math notranslate nohighlight">\(x\)</span> randomly (uniformly) distributed between 0 and 1, <span class="math notranslate nohighlight">\(\beta_0 = -1\)</span>, <span class="math notranslate nohighlight">\(\beta_1 = 0.85\)</span>, and <span class="math notranslate nohighlight">\(\varepsilon\)</span> randomly (normally) distributed with mean 0 and standard deviation 0.1. Make a scatterplot of these data.</p>
</li>
<li><p>Create a function that calculates the sum of the squared residuals (errors between predicted and observed data) given a vector <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> of input parameters. Use SciPy’s <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html"><code class="docutils literal notranslate"><span class="pre">scipy.optimize.minimize</span></code></a> to find the values of <span class="math notranslate nohighlight">\(\beta_0\)</span> and <span class="math notranslate nohighlight">\(\beta_1\)</span> that minimize this function.</p></li>
<li><p>Plot the best-fit line through the data defined by the regression coefficients you found above.</p></li>
</ol>
</div>
<section id="id1">
<h3>Solution:<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">500</span>

<span class="n">beta</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.85</span><span class="p">]</span>

<span class="n">x_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>  <span class="c1"># rand is uniformly distributed in [0, 1]</span>
<span class="n">eps_samples</span> <span class="o">=</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>  <span class="c1"># randn is N(0, 1)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">beta</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">beta</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">x_samples</span> <span class="o">+</span> <span class="n">eps_samples</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_samples</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/fitting_basic_models_4_0.svg" src="../_images/fitting_basic_models_4_0.svg" /></div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">err</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y</span> <span class="o">-</span> <span class="p">(</span><span class="n">beta</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">beta</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>

<span class="n">res</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">err</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">x_samples</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
<span class="n">beta_pred</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span>

<span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x_samples</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span><span class="n">x_samples</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">beta_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">beta_pred</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">x1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_samples</span><span class="p">,</span> <span class="n">y</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Best fit&quot;</span><span class="p">,</span><span class="s2">&quot;Data&quot;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/fitting_basic_models_5_0.svg" src="../_images/fitting_basic_models_5_0.svg" /></div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./models"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="intro.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Modeling neural data</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="simulation_models.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Fitting simulated models</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By John Pearson<br/>
  
      &copy; Copyright 2023.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>